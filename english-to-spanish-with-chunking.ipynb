{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711035286804
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1721150839381
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import installed libraries\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "from openai import AzureOpenAI\n",
        "import re\n",
        "\n",
        "# from semantic_kernel.text import split_markdown_paragraph\n",
        "# chunking the text into paragraphs using markdown\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "# load environment variables\n",
        "load_dotenv(override=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n"
          ]
        }
      ],
      "source": [
        "# loading the markdown file\n",
        "markdown_file = os.path.join(os.getcwd(), \"data\", \"DRAFT_Acolad_2023 - English.md\")\n",
        "\n",
        "chunked_data = []\n",
        "\n",
        "with open(markdown_file, 'r') as file:\n",
        "    data = file.read()\n",
        "\n",
        "    headers_to_split_on = [\n",
        "        (\"#\", \"Header 1\"),\n",
        "        (\"##\", \"Header 2\"),\n",
        "        (\"###\", \"Header 3\"),\n",
        "    ]\n",
        "\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
        "        headers_to_split_on=headers_to_split_on, strip_headers=False\n",
        "    )\n",
        "    chunked_data = markdown_splitter.split_text(data)\n",
        "\n",
        "    print(len(chunked_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initializing the Azure OpenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1721150850295
        }
      },
      "outputs": [],
      "source": [
        "# define openai Client\n",
        "aoai_api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
        "aoai_api_endpoint =  os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "aoai_api_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=aoai_api_key,\n",
        "    api_version=\"2024-08-01-preview\",\n",
        "    azure_endpoint=aoai_api_endpoint\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1721150856670
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "translated = []\n",
        "\n",
        "for chunk in chunked_data:\n",
        "        \n",
        "\n",
        "    systemPrompt = f\"\"\"\n",
        "    Your Task is to translate the given text from English to Spanish:\n",
        "    DO NOT RESPOND WITH ANYTHING ELSE EXCEPT THE TRANSLATION.\n",
        "    MAKE SURE TO KEEP THE MARKDOWN FORMATTING, THAT INCLUDES HEADERS, BULLETS, TABLES, ETC BUT DO NOT BOTHER WRAPPING IT AS MARKDOWN.\n",
        "    Task:\n",
        "        Step 1: Translate the given text to English, ensuring that the meaning (semantics) of the original text is preserved as closely as possible.\n",
        "        Step 2: Do not translate any text containing \"trademark symbols\" (™ or ®). Keep these parts as is.\n",
        "        Below is the text for translation:\n",
        "        ----------------------------------------\n",
        "\n",
        "        {chunk}\n",
        "    \"\"\"\n",
        "\n",
        "    conversaion = [\n",
        "        {\"role\": \"system\", \"content\": systemPrompt},\n",
        "        {\"role\": \"user\", \"content\": \"give me the translation in Spanish\"}\n",
        "    ]\n",
        "\n",
        "    # Send the conversation to the API\n",
        "    response = client.chat.completions.create(\n",
        "        model=aoai_api_deployment_name, # The deployment name you chose when you deployed the GPT-35-Turbo or GPT-4 model.\n",
        "        messages=conversaion,\n",
        "        temperature=0.0,\n",
        "    )\n",
        "\n",
        "    # Print the assistant's response\n",
        "    responseText = response.choices[0].message.content\n",
        "    translated.append(responseText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(len(translated))\n",
        "# concat all the translated text and create a new markdown file\n",
        "translated_md = \"\\n\\n\".join(translated) \n",
        "\n",
        "\n",
        "# save the responseText to a file with utf-8 encoding\n",
        "output_file = os.path.join(os.getcwd(), \"data\", \"DRAFT_Acolad_2023 - Spanish test.md\")\n",
        "with open(output_file, 'w', encoding='utf-8') as file:\n",
        "    file.write(translated_md)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "newenvtf"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
